{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10129 images belonging to 2 classes.\n",
      "Found 532 images belonging to 2 classes.\n",
      "Training with combined dataset\n",
      "Epoch 1/10\n",
      "633/633 [==============================] - 202s 317ms/step - loss: 0.5376 - accuracy: 0.7469 - val_loss: 0.3800 - val_accuracy: 0.8617\n",
      "Epoch 2/10\n",
      "633/633 [==============================] - 200s 316ms/step - loss: 0.4785 - accuracy: 0.7922 - val_loss: 0.3902 - val_accuracy: 0.8371\n",
      "Epoch 3/10\n",
      "633/633 [==============================] - 173s 274ms/step - loss: 0.4696 - accuracy: 0.7952 - val_loss: 0.3828 - val_accuracy: 0.8447\n",
      "Epoch 4/10\n",
      "633/633 [==============================] - 163s 257ms/step - loss: 0.4670 - accuracy: 0.8001 - val_loss: 0.3796 - val_accuracy: 0.8409\n",
      "Epoch 5/10\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 0.4643 - accuracy: 0.8000 - val_loss: 0.3956 - val_accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "633/633 [==============================] - 158s 250ms/step - loss: 0.4600 - accuracy: 0.8027 - val_loss: 0.3705 - val_accuracy: 0.8504\n",
      "Epoch 7/10\n",
      "633/633 [==============================] - 161s 254ms/step - loss: 0.4599 - accuracy: 0.8007 - val_loss: 0.3981 - val_accuracy: 0.8220\n",
      "Epoch 8/10\n",
      "633/633 [==============================] - 156s 246ms/step - loss: 0.4591 - accuracy: 0.8010 - val_loss: 0.3860 - val_accuracy: 0.8258\n",
      "Epoch 9/10\n",
      "633/633 [==============================] - 155s 245ms/step - loss: 0.4567 - accuracy: 0.8021 - val_loss: 0.3754 - val_accuracy: 0.8333\n",
      "Epoch 10/10\n",
      "633/633 [==============================] - 161s 254ms/step - loss: 0.4554 - accuracy: 0.8046 - val_loss: 0.3773 - val_accuracy: 0.8295\n",
      "Model saved as model_combined.h5\n",
      "Evaluating the model on the test data\n",
      "33/33 [==============================] - 10s 277ms/step - loss: 0.3800 - accuracy: 0.8295\n",
      "Test Loss: 0.3799971044063568\n",
      "Test Accuracy: 0.8295454382896423\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "base_dir = 'D:/PKG - C-NMC 2019/C-NMC_training_data'\n",
    "folds = ['fold_0', 'fold_1', 'fold_2']\n",
    "combined_dir = 'D:/PKG - C-NMC 2019/C-NMC_combined_data'\n",
    "all_dir = os.path.join(combined_dir, 'all')\n",
    "hem_dir = os.path.join(combined_dir, 'hem')\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 64, 64  # Reduced image size\n",
    "batch_size = 16  # Increased batch size\n",
    "epochs = 10  # Reduced number of epochs\n",
    "\n",
    "# Function to combine directories\n",
    "def combine_directories(base_dir, folds, all_dir, hem_dir):\n",
    "    if not os.path.exists(all_dir):\n",
    "        os.makedirs(all_dir)\n",
    "    if not os.path.exists(hem_dir):\n",
    "        os.makedirs(hem_dir)\n",
    "    \n",
    "    for fold in folds:\n",
    "        fold_dir = os.path.join(base_dir, fold)\n",
    "        for category in ['all', 'hem']:\n",
    "            category_dir = os.path.join(fold_dir, category)\n",
    "            combined_category_dir = all_dir if category == 'all' else hem_dir\n",
    "            for filename in os.listdir(category_dir):\n",
    "                if filename.endswith('.bmp'):\n",
    "                    src = os.path.join(category_dir, filename)\n",
    "                    dst = os.path.join(combined_category_dir, filename)\n",
    "                    if not os.path.exists(dst):  # Avoid duplicates\n",
    "                        shutil.copy(src, dst)\n",
    "\n",
    "combine_directories(base_dir, folds, all_dir, hem_dir)\n",
    "\n",
    "# Data Generators\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.05)  # 5% for validation (test)\n",
    "\n",
    "def create_data_generators(combined_dir, img_width, img_height, batch_size):\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='training'  # 95% for training\n",
    "    )\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='validation'  # 5% for testing\n",
    "    )\n",
    "    return train_generator, test_generator\n",
    "\n",
    "train_generator, test_generator = create_data_generators(combined_dir, img_width, img_height, batch_size)\n",
    "\n",
    "# Define a smaller CNN model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the model with the combined dataset\n",
    "print(\"Training with combined dataset\")\n",
    "model = create_model()\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('model_combined.h5')\n",
    "print(\"Model saved as model_combined.h5\")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(\"Evaluating the model on the test data\")\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10129 images belonging to 2 classes.\n",
      "Found 532 images belonging to 2 classes.\n",
      "Training with combined dataset\n",
      "Epoch 1/10\n",
      "316/316 [==============================] - 127s 398ms/step - loss: 0.5246 - accuracy: 0.7541 - val_loss: 0.4213 - val_accuracy: 0.8242\n",
      "Epoch 2/10\n",
      "316/316 [==============================] - 123s 388ms/step - loss: 0.4698 - accuracy: 0.7968 - val_loss: 0.4236 - val_accuracy: 0.8203\n",
      "Epoch 3/10\n",
      "316/316 [==============================] - 125s 395ms/step - loss: 0.4656 - accuracy: 0.7963 - val_loss: 0.4026 - val_accuracy: 0.8301\n",
      "Epoch 4/10\n",
      "316/316 [==============================] - 127s 401ms/step - loss: 0.4635 - accuracy: 0.7981 - val_loss: 0.4527 - val_accuracy: 0.8027\n",
      "Epoch 5/10\n",
      "316/316 [==============================] - 123s 389ms/step - loss: 0.4615 - accuracy: 0.8017 - val_loss: 0.4254 - val_accuracy: 0.8262\n",
      "Epoch 6/10\n",
      "316/316 [==============================] - 121s 383ms/step - loss: 0.4588 - accuracy: 0.8026 - val_loss: 0.4081 - val_accuracy: 0.8262\n",
      "Epoch 7/10\n",
      "316/316 [==============================] - 121s 384ms/step - loss: 0.4570 - accuracy: 0.8011 - val_loss: 0.4082 - val_accuracy: 0.8223\n",
      "Epoch 8/10\n",
      "316/316 [==============================] - 122s 387ms/step - loss: 0.4534 - accuracy: 0.7973 - val_loss: 0.4241 - val_accuracy: 0.8047\n",
      "Epoch 9/10\n",
      "316/316 [==============================] - 121s 383ms/step - loss: 0.4544 - accuracy: 0.8027 - val_loss: 0.4206 - val_accuracy: 0.8086\n",
      "Epoch 10/10\n",
      "316/316 [==============================] - 122s 388ms/step - loss: 0.4538 - accuracy: 0.8047 - val_loss: 0.3970 - val_accuracy: 0.8262\n",
      "Model saved as model_improve_1_combined.h5\n",
      "Evaluating the model on the test data\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.3994 - accuracy: 0.8242\n",
      "Test Loss: 0.39938634634017944\n",
      "Test Accuracy: 0.82421875\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "base_dir = 'D:/PKG - C-NMC 2019/C-NMC_training_data'\n",
    "folds = ['fold_0', 'fold_1', 'fold_2']\n",
    "combined_dir = 'D:/PKG - C-NMC 2019/C-NMC_combined_data'\n",
    "all_dir = os.path.join(combined_dir, 'all')\n",
    "hem_dir = os.path.join(combined_dir, 'hem')\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 128, 128  # Reduced image size\n",
    "batch_size = 32  # Increased batch size\n",
    "epochs = 10  # Reduced number of epochs\n",
    "\n",
    "# Function to combine directories\n",
    "def combine_directories(base_dir, folds, all_dir, hem_dir):\n",
    "    if not os.path.exists(all_dir):\n",
    "        os.makedirs(all_dir)\n",
    "    if not os.path.exists(hem_dir):\n",
    "        os.makedirs(hem_dir)\n",
    "    \n",
    "    for fold in folds:\n",
    "        fold_dir = os.path.join(base_dir, fold)\n",
    "        for category in ['all', 'hem']:\n",
    "            category_dir = os.path.join(fold_dir, category)\n",
    "            combined_category_dir = all_dir if category == 'all' else hem_dir\n",
    "            for filename in os.listdir(category_dir):\n",
    "                if filename.endswith('.bmp'):\n",
    "                    src = os.path.join(category_dir, filename)\n",
    "                    dst = os.path.join(combined_category_dir, filename)\n",
    "                    if not os.path.exists(dst):  # Avoid duplicates\n",
    "                        shutil.copy(src, dst)\n",
    "\n",
    "combine_directories(base_dir, folds, all_dir, hem_dir)\n",
    "\n",
    "# Data Generators\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.05)  # 5% for validation (test)\n",
    "\n",
    "def create_data_generators(combined_dir, img_width, img_height, batch_size):\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='training'  # 95% for training\n",
    "    )\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='validation'  # 5% for testing\n",
    "    )\n",
    "    return train_generator, test_generator\n",
    "\n",
    "train_generator, test_generator = create_data_generators(combined_dir, img_width, img_height, batch_size)\n",
    "\n",
    "# Define a smaller CNN model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the model with the combined dataset\n",
    "print(\"Training with combined dataset\")\n",
    "model1 = create_model()\n",
    "history = model1.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model1.save('model_improve_1_combined.h5')\n",
    "print(\"Model saved as model_improve_1_combined.h5\")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(\"Evaluating the model on the test data\")\n",
    "test_loss, test_accuracy = model1.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10129 images belonging to 2 classes.\n",
      "Found 532 images belonging to 2 classes.\n",
      "Training with combined dataset\n",
      "Epoch 1/20\n",
      "633/633 [==============================] - 171s 267ms/step - loss: 0.4899 - accuracy: 0.7834 - val_loss: 0.4298 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "633/633 [==============================] - 211s 334ms/step - loss: 0.4664 - accuracy: 0.7972 - val_loss: 0.4146 - val_accuracy: 0.8182 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "633/633 [==============================] - 217s 343ms/step - loss: 0.4602 - accuracy: 0.8020 - val_loss: 0.3831 - val_accuracy: 0.8314 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "633/633 [==============================] - 175s 276ms/step - loss: 0.4501 - accuracy: 0.8027 - val_loss: 0.4072 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "633/633 [==============================] - 160s 252ms/step - loss: 0.4519 - accuracy: 0.8042 - val_loss: 0.3871 - val_accuracy: 0.8466 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "633/633 [==============================] - 164s 258ms/step - loss: 0.4465 - accuracy: 0.8062 - val_loss: 0.3622 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "633/633 [==============================] - 160s 253ms/step - loss: 0.4391 - accuracy: 0.8115 - val_loss: 0.3714 - val_accuracy: 0.8485 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "633/633 [==============================] - 157s 248ms/step - loss: 0.4313 - accuracy: 0.8127 - val_loss: 0.4334 - val_accuracy: 0.8068 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "633/633 [==============================] - 123s 194ms/step - loss: 0.4209 - accuracy: 0.8172 - val_loss: 0.3419 - val_accuracy: 0.8655 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "633/633 [==============================] - 104s 164ms/step - loss: 0.4124 - accuracy: 0.8212 - val_loss: 0.3468 - val_accuracy: 0.8485 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "633/633 [==============================] - 115s 181ms/step - loss: 0.3957 - accuracy: 0.8295 - val_loss: 0.4362 - val_accuracy: 0.8144 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.8346\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "633/633 [==============================] - 131s 207ms/step - loss: 0.3769 - accuracy: 0.8346 - val_loss: 0.3482 - val_accuracy: 0.8561 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "633/633 [==============================] - 128s 202ms/step - loss: 0.3322 - accuracy: 0.8556 - val_loss: 0.4321 - val_accuracy: 0.7973 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3086 - accuracy: 0.8663Restoring model weights from the end of the best epoch: 9.\n",
      "633/633 [==============================] - 124s 196ms/step - loss: 0.3086 - accuracy: 0.8663 - val_loss: 0.4012 - val_accuracy: 0.8201 - lr: 5.0000e-04\n",
      "Epoch 14: early stopping\n",
      "Model saved as model_improve_2_combined.h5\n",
      "Evaluating the model on the test data\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.3414 - accuracy: 0.8655\n",
      "Test Loss: 0.3413754105567932\n",
      "Test Accuracy: 0.8655303120613098\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "base_dir = 'D:/PKG - C-NMC 2019/C-NMC_training_data'\n",
    "folds = ['fold_0', 'fold_1', 'fold_2']\n",
    "combined_dir = 'D:/PKG - C-NMC 2019/C-NMC_combined_data'\n",
    "all_dir = os.path.join(combined_dir, 'all')\n",
    "hem_dir = os.path.join(combined_dir, 'hem')\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 128, 128  # Image size\n",
    "batch_size = 16  # Batch size\n",
    "epochs = 20  # Number of epochs\n",
    "\n",
    "# Function to combine directories\n",
    "def combine_directories(base_dir, folds, all_dir, hem_dir):\n",
    "    if not os.path.exists(all_dir):\n",
    "        os.makedirs(all_dir)\n",
    "    if not os.path.exists(hem_dir):\n",
    "        os.makedirs(hem_dir)\n",
    "    \n",
    "    for fold in folds:\n",
    "        fold_dir = os.path.join(base_dir, fold)\n",
    "        for category in ['all', 'hem']:\n",
    "            category_dir = os.path.join(fold_dir, category)\n",
    "            combined_category_dir = all_dir if category == 'all' else hem_dir\n",
    "            for filename in os.listdir(category_dir):\n",
    "                if filename.endswith('.bmp'):\n",
    "                    src = os.path.join(category_dir, filename)\n",
    "                    dst = os.path.join(combined_category_dir, filename)\n",
    "                    if not os.path.exists(dst):  # Avoid duplicates\n",
    "                        shutil.copy(src, dst)\n",
    "\n",
    "combine_directories(base_dir, folds, all_dir, hem_dir)\n",
    "\n",
    "# Data Generators\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.05)  # 5% for validation\n",
    "\n",
    "def create_data_generators(combined_dir, img_width, img_height, batch_size):\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='training'  # 95% for training\n",
    "    )\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='validation'  # 5% for validation\n",
    "    )\n",
    "    return train_generator, test_generator\n",
    "\n",
    "train_generator, test_generator = create_data_generators(combined_dir, img_width, img_height, batch_size)\n",
    "\n",
    "# Define the CNN model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks for dynamic learning rate and early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with the combined dataset\n",
    "print(\"Training with combined dataset\")\n",
    "model2 = create_model()\n",
    "history = model2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model2.save('model_improve_2_combined.h5')\n",
    "print(\"Model saved as model_improve_2_combined.h5\")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(\"Evaluating the model on the test data\")\n",
    "test_loss, test_accuracy = model2.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10129 images belonging to 2 classes.\n",
      "Found 532 images belonging to 2 classes.\n",
      "Training with combined dataset\n",
      "Epoch 1/20\n",
      "633/633 [==============================] - 179s 280ms/step - loss: 0.4921 - accuracy: 0.7835 - val_loss: 0.4101 - val_accuracy: 0.8239 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "633/633 [==============================] - 160s 253ms/step - loss: 0.4652 - accuracy: 0.8001 - val_loss: 0.4162 - val_accuracy: 0.8182 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "633/633 [==============================] - 149s 235ms/step - loss: 0.4576 - accuracy: 0.8026 - val_loss: 0.3881 - val_accuracy: 0.8258 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "633/633 [==============================] - 198s 313ms/step - loss: 0.4565 - accuracy: 0.8020 - val_loss: 0.3777 - val_accuracy: 0.8295 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "633/633 [==============================] - 157s 247ms/step - loss: 0.4465 - accuracy: 0.8086 - val_loss: 0.3678 - val_accuracy: 0.8314 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "633/633 [==============================] - 158s 250ms/step - loss: 0.4433 - accuracy: 0.8088 - val_loss: 0.3901 - val_accuracy: 0.8030 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "633/633 [==============================] - 161s 254ms/step - loss: 0.4384 - accuracy: 0.8090 - val_loss: 0.3580 - val_accuracy: 0.8428 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "633/633 [==============================] - 155s 245ms/step - loss: 0.4327 - accuracy: 0.8153 - val_loss: 0.3333 - val_accuracy: 0.8674 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "633/633 [==============================] - 175s 276ms/step - loss: 0.4186 - accuracy: 0.8215 - val_loss: 0.3458 - val_accuracy: 0.8561 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "633/633 [==============================] - 126s 200ms/step - loss: 0.4049 - accuracy: 0.8271 - val_loss: 0.3926 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8355\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "633/633 [==============================] - 135s 214ms/step - loss: 0.3862 - accuracy: 0.8355 - val_loss: 0.3521 - val_accuracy: 0.8523 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "633/633 [==============================] - 128s 202ms/step - loss: 0.3435 - accuracy: 0.8528 - val_loss: 0.3377 - val_accuracy: 0.8542 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "633/633 [==============================] - 130s 205ms/step - loss: 0.3240 - accuracy: 0.8638 - val_loss: 0.3006 - val_accuracy: 0.8883 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "633/633 [==============================] - 130s 206ms/step - loss: 0.3057 - accuracy: 0.8696 - val_loss: 0.3773 - val_accuracy: 0.8447 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "633/633 [==============================] - 127s 200ms/step - loss: 0.2866 - accuracy: 0.8769 - val_loss: 0.3655 - val_accuracy: 0.8598 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.8844\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "633/633 [==============================] - 148s 234ms/step - loss: 0.2720 - accuracy: 0.8844 - val_loss: 0.3068 - val_accuracy: 0.8807 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "633/633 [==============================] - 123s 195ms/step - loss: 0.2339 - accuracy: 0.9036 - val_loss: 0.3530 - val_accuracy: 0.8655 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9108Restoring model weights from the end of the best epoch: 13.\n",
      "633/633 [==============================] - 123s 194ms/step - loss: 0.2183 - accuracy: 0.9108 - val_loss: 0.3444 - val_accuracy: 0.8788 - lr: 2.5000e-04\n",
      "Epoch 18: early stopping\n",
      "Model saved as model_improve_3_combined.h5\n",
      "Evaluating the model on the test data\n",
      "33/33 [==============================] - 2s 44ms/step - loss: 0.3059 - accuracy: 0.8864\n",
      "Test Loss: 0.3059\n",
      "Test Accuracy: 0.8864\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Define paths\n",
    "base_dir = r'D:\\PKG - C-NMC 2019\\C-NMC_training_data'\n",
    "folds = ['fold_0', 'fold_1', 'fold_2']\n",
    "combined_dir = r'D:\\PKG - C-NMC 2019\\C-NMC_combined_data'\n",
    "all_dir = os.path.join(combined_dir, 'all')\n",
    "hem_dir = os.path.join(combined_dir, 'hem')\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 128, 128  # Image size\n",
    "batch_size = 16  # Batch size\n",
    "epochs = 20  # Number of epochs\n",
    "\n",
    "# Function to combine directories\n",
    "def combine_directories(base_dir, folds, all_dir, hem_dir):\n",
    "    if not os.path.exists(all_dir):\n",
    "        os.makedirs(all_dir)\n",
    "    if not os.path.exists(hem_dir):\n",
    "        os.makedirs(hem_dir)\n",
    "    \n",
    "    for fold in folds:\n",
    "        fold_dir = os.path.join(base_dir, fold)\n",
    "        for category in ['all', 'hem']:\n",
    "            category_dir = os.path.join(fold_dir, category)\n",
    "            combined_category_dir = all_dir if category == 'all' else hem_dir\n",
    "            if os.path.exists(category_dir):\n",
    "                for filename in os.listdir(category_dir):\n",
    "                    if filename.endswith('.bmp'):\n",
    "                        src = os.path.join(category_dir, filename)\n",
    "                        dst = os.path.join(combined_category_dir, filename)\n",
    "                        if not os.path.exists(dst):  # Avoid duplicates\n",
    "                            shutil.copy(src, dst)\n",
    "            else:\n",
    "                print(f\"Warning: The directory {category_dir} does not exist.\")\n",
    "\n",
    "combine_directories(base_dir, folds, all_dir, hem_dir)\n",
    "\n",
    "# Data Generators\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.05)  # 5% for validation\n",
    "\n",
    "def create_data_generators(combined_dir, img_width, img_height, batch_size):\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='training'  # 95% for training\n",
    "    )\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='validation'  # 5% for validation\n",
    "    )\n",
    "    return train_generator, test_generator\n",
    "\n",
    "train_generator, test_generator = create_data_generators(combined_dir, img_width, img_height, batch_size)\n",
    "\n",
    "# Define the CNN model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks for dynamic learning rate and early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with the combined dataset\n",
    "print(\"Training with combined dataset\")\n",
    "model3 = create_model()\n",
    "history = model3.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model3.save('model_improve_3_combined.h5')\n",
    "print(\"Model saved as model_improve_3_combined.h5\")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(\"Evaluating the model on the test data\")\n",
    "test_loss, test_accuracy = model3.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10129 images belonging to 2 classes.\n",
      "Found 532 images belonging to 2 classes.\n",
      "Training with combined dataset\n",
      "Epoch 1/20\n",
      "633/633 [==============================] - 219s 342ms/step - loss: 0.4889 - accuracy: 0.7798 - val_loss: 0.4042 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "633/633 [==============================] - 121s 190ms/step - loss: 0.4664 - accuracy: 0.8004 - val_loss: 0.3750 - val_accuracy: 0.8466 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "633/633 [==============================] - 79s 125ms/step - loss: 0.4594 - accuracy: 0.8022 - val_loss: 0.4263 - val_accuracy: 0.8049 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "633/633 [==============================] - 71s 112ms/step - loss: 0.4550 - accuracy: 0.8023 - val_loss: 0.4013 - val_accuracy: 0.8239 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8076\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "633/633 [==============================] - 71s 113ms/step - loss: 0.4506 - accuracy: 0.8076 - val_loss: 0.3985 - val_accuracy: 0.8239 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "633/633 [==============================] - 69s 109ms/step - loss: 0.4363 - accuracy: 0.8092 - val_loss: 0.3687 - val_accuracy: 0.8390 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "633/633 [==============================] - 70s 110ms/step - loss: 0.4289 - accuracy: 0.8173 - val_loss: 0.3725 - val_accuracy: 0.8371 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "633/633 [==============================] - 74s 117ms/step - loss: 0.4167 - accuracy: 0.8251 - val_loss: 0.3589 - val_accuracy: 0.8466 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "633/633 [==============================] - 96s 152ms/step - loss: 0.4071 - accuracy: 0.8280 - val_loss: 0.4177 - val_accuracy: 0.8163 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "633/633 [==============================] - 90s 143ms/step - loss: 0.3977 - accuracy: 0.8286 - val_loss: 0.3301 - val_accuracy: 0.8693 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "633/633 [==============================] - 85s 134ms/step - loss: 0.3802 - accuracy: 0.8389 - val_loss: 0.3611 - val_accuracy: 0.8485 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "633/633 [==============================] - 89s 140ms/step - loss: 0.3671 - accuracy: 0.8451 - val_loss: 0.3924 - val_accuracy: 0.8523 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8399\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "633/633 [==============================] - 86s 136ms/step - loss: 0.3721 - accuracy: 0.8399 - val_loss: 0.3681 - val_accuracy: 0.8504 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "633/633 [==============================] - 78s 124ms/step - loss: 0.3190 - accuracy: 0.8621 - val_loss: 0.3210 - val_accuracy: 0.8977 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "633/633 [==============================] - 81s 129ms/step - loss: 0.2989 - accuracy: 0.8736 - val_loss: 0.3481 - val_accuracy: 0.8598 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "633/633 [==============================] - 83s 131ms/step - loss: 0.2914 - accuracy: 0.8800 - val_loss: 0.3414 - val_accuracy: 0.8769 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.8851\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "633/633 [==============================] - 82s 129ms/step - loss: 0.2701 - accuracy: 0.8851 - val_loss: 0.4051 - val_accuracy: 0.8485 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "633/633 [==============================] - 88s 139ms/step - loss: 0.2451 - accuracy: 0.9029 - val_loss: 0.3406 - val_accuracy: 0.8845 - lr: 1.2500e-04\n",
      "Epoch 19/20\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.9042Restoring model weights from the end of the best epoch: 14.\n",
      "633/633 [==============================] - 90s 143ms/step - loss: 0.2339 - accuracy: 0.9042 - val_loss: 0.3304 - val_accuracy: 0.8826 - lr: 1.2500e-04\n",
      "Epoch 19: early stopping\n",
      "Model saved as model_improve_4_combined.h5\n",
      "Evaluating the model on the test data\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3209 - accuracy: 0.8958\n",
      "Test Loss: 0.3209\n",
      "Test Accuracy: 0.8958\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "base_dir = 'D:/PKG - C-NMC 2019/C-NMC_training_data'\n",
    "folds = ['fold_0', 'fold_1', 'fold_2']\n",
    "combined_dir = 'D:/PKG - C-NMC 2019/C-NMC_combined_data'\n",
    "all_dir = os.path.join(combined_dir, 'all')\n",
    "hem_dir = os.path.join(combined_dir, 'hem')\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 128, 128  # Image size\n",
    "batch_size = 16  # Batch size\n",
    "epochs = 20  # Number of epochs\n",
    "\n",
    "# Function to combine directories\n",
    "def combine_directories(base_dir, folds, all_dir, hem_dir):\n",
    "    if not os.path.exists(all_dir):\n",
    "        os.makedirs(all_dir)\n",
    "    if not os.path.exists(hem_dir):\n",
    "        os.makedirs(hem_dir)\n",
    "    \n",
    "    for fold in folds:\n",
    "        fold_dir = os.path.join(base_dir, fold)\n",
    "        for category in ['all', 'hem']:\n",
    "            category_dir = os.path.join(fold_dir, category)\n",
    "            combined_category_dir = all_dir if category == 'all' else hem_dir\n",
    "            if os.path.exists(category_dir):\n",
    "                for filename in os.listdir(category_dir):\n",
    "                    if filename.endswith('.bmp'):\n",
    "                        src = os.path.join(category_dir, filename)\n",
    "                        dst = os.path.join(combined_category_dir, filename)\n",
    "                        if not os.path.exists(dst):  # Avoid duplicates\n",
    "                            shutil.copy(src, dst)\n",
    "\n",
    "combine_directories(base_dir, folds, all_dir, hem_dir)\n",
    "\n",
    "# Data Generators\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.05)  # 5% for validation\n",
    "\n",
    "def create_data_generators(combined_dir, img_width, img_height, batch_size):\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='training'  # 95% for training\n",
    "    )\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='validation'  # 5% for validation\n",
    "    )\n",
    "    return train_generator, test_generator\n",
    "\n",
    "train_generator, test_generator = create_data_generators(combined_dir, img_width, img_height, batch_size)\n",
    "\n",
    "# Define the CNN model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks for dynamic learning rate and early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with the combined dataset\n",
    "print(\"Training with combined dataset\")\n",
    "model4 = create_model()\n",
    "history = model4.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model4.save('model_improve_4_combined.h5')\n",
    "print(\"Model saved as model_improve_4_combined.h5\")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(\"Evaluating the model on the test data\")\n",
    "test_loss, test_accuracy = model4.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10129 images belonging to 2 classes.\n",
      "Found 532 images belonging to 2 classes.\n",
      "Training with combined dataset\n",
      "Epoch 1/30\n",
      "633/633 [==============================] - 151s 237ms/step - loss: 0.5187 - accuracy: 0.7625 - val_loss: 0.3856 - val_accuracy: 0.8390 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "633/633 [==============================] - 145s 229ms/step - loss: 0.4730 - accuracy: 0.7921 - val_loss: 0.3848 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "633/633 [==============================] - 164s 259ms/step - loss: 0.4672 - accuracy: 0.7952 - val_loss: 0.3760 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "633/633 [==============================] - 236s 373ms/step - loss: 0.4632 - accuracy: 0.7948 - val_loss: 0.4430 - val_accuracy: 0.8030 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "633/633 [==============================] - 178s 281ms/step - loss: 0.4648 - accuracy: 0.7991 - val_loss: 0.4064 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.7979\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "633/633 [==============================] - 151s 238ms/step - loss: 0.4609 - accuracy: 0.7979 - val_loss: 0.4013 - val_accuracy: 0.8163 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "633/633 [==============================] - 148s 234ms/step - loss: 0.4530 - accuracy: 0.8015 - val_loss: 0.3964 - val_accuracy: 0.8201 - lr: 5.0000e-04\n",
      "Epoch 8/30\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8022Restoring model weights from the end of the best epoch: 3.\n",
      "633/633 [==============================] - 149s 235ms/step - loss: 0.4516 - accuracy: 0.8022 - val_loss: 0.3998 - val_accuracy: 0.8201 - lr: 5.0000e-04\n",
      "Epoch 8: early stopping\n",
      "Model saved as model_improve_5_combined.h5\n",
      "Evaluating the model on the test data\n",
      "33/33 [==============================] - 2s 45ms/step - loss: 0.3760 - accuracy: 0.8333\n",
      "Test Loss: 0.3760\n",
      "Test Accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Define paths\n",
    "base_dir = r'D:\\PKG - C-NMC 2019\\C-NMC_training_data'\n",
    "folds = ['fold_0', 'fold_1', 'fold_2']\n",
    "combined_dir = r'D:\\PKG - C-NMC 2019\\C-NMC_combined_data'\n",
    "all_dir = os.path.join(combined_dir, 'all')\n",
    "hem_dir = os.path.join(combined_dir, 'hem')\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 128, 128  \n",
    "batch_size = 16 \n",
    "epochs = 30  \n",
    "\n",
    "# Function to combine directories\n",
    "def combine_directories(base_dir, folds, all_dir, hem_dir):\n",
    "    if not os.path.exists(all_dir):\n",
    "        os.makedirs(all_dir)\n",
    "    if not os.path.exists(hem_dir):\n",
    "        os.makedirs(hem_dir)\n",
    "    \n",
    "    for fold in folds:\n",
    "        fold_dir = os.path.join(base_dir, fold)\n",
    "        for category in ['all', 'hem']:\n",
    "            category_dir = os.path.join(fold_dir, category)\n",
    "            combined_category_dir = all_dir if category == 'all' else hem_dir\n",
    "            if os.path.exists(category_dir):\n",
    "                for filename in os.listdir(category_dir):\n",
    "                    if filename.endswith('.bmp'):\n",
    "                        src = os.path.join(category_dir, filename)\n",
    "                        dst = os.path.join(combined_category_dir, filename)\n",
    "                        if not os.path.exists(dst):  # Avoid duplicates\n",
    "                            shutil.copy(src, dst)\n",
    "            else:\n",
    "                print(f\"Warning: The directory {category_dir} does not exist.\")\n",
    "\n",
    "combine_directories(base_dir, folds, all_dir, hem_dir)\n",
    "\n",
    "# Data Generator\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.05)  # 5% for validation\n",
    "\n",
    "def create_data_generators(combined_dir, img_width, img_height, batch_size):\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='training'  # 95% for training\n",
    "    )\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='validation'  # 5% for validation\n",
    "    )\n",
    "    return train_generator, test_generator\n",
    "\n",
    "train_generator, test_generator = create_data_generators(combined_dir, img_width, img_height, batch_size)\n",
    "\n",
    "# CNN model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(img_width, img_height, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='softmax', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks for dynamic learning rate and early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training with combined dataset\")\n",
    "model5 = create_model()\n",
    "history = model5.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model5.save('model_improve_5_combined.h5')\n",
    "print(\"Model saved as model_improve_5_combined.h5\")\n",
    "\n",
    "# Evaluating the model on the test data\n",
    "print(\"Evaluating the model on the test data\")\n",
    "test_loss, test_accuracy = model5.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10129 images belonging to 2 classes.\n",
      "Found 532 images belonging to 2 classes.\n",
      "Training with combined dataset\n",
      "Epoch 1/30\n",
      "633/633 [==============================] - 142s 222ms/step - loss: 0.5542 - accuracy: 0.7407 - val_loss: 0.4362 - val_accuracy: 0.8049 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "633/633 [==============================] - 151s 239ms/step - loss: 0.5177 - accuracy: 0.7887 - val_loss: 0.3966 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "633/633 [==============================] - 142s 225ms/step - loss: 0.4884 - accuracy: 0.7887 - val_loss: 0.3930 - val_accuracy: 0.8466 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "633/633 [==============================] - 144s 227ms/step - loss: 0.4766 - accuracy: 0.7966 - val_loss: 0.4474 - val_accuracy: 0.8182 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "633/633 [==============================] - 140s 221ms/step - loss: 0.4722 - accuracy: 0.7972 - val_loss: 0.4167 - val_accuracy: 0.8106 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.4617 - accuracy: 0.8005\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "633/633 [==============================] - 140s 221ms/step - loss: 0.4617 - accuracy: 0.8005 - val_loss: 0.4182 - val_accuracy: 0.8277 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "633/633 [==============================] - 160s 253ms/step - loss: 0.4622 - accuracy: 0.8019 - val_loss: 0.3870 - val_accuracy: 0.8239 - lr: 5.0000e-04\n",
      "Epoch 8/30\n",
      "633/633 [==============================] - 148s 233ms/step - loss: 0.4561 - accuracy: 0.8050 - val_loss: 0.3969 - val_accuracy: 0.8201 - lr: 5.0000e-04\n",
      "Epoch 9/30\n",
      "633/633 [==============================] - 151s 238ms/step - loss: 0.4556 - accuracy: 0.8060 - val_loss: 0.3733 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
      "Epoch 10/30\n",
      "633/633 [==============================] - 145s 230ms/step - loss: 0.4539 - accuracy: 0.8072 - val_loss: 0.3964 - val_accuracy: 0.8258 - lr: 5.0000e-04\n",
      "Epoch 11/30\n",
      "633/633 [==============================] - 144s 227ms/step - loss: 0.4499 - accuracy: 0.8058 - val_loss: 0.3752 - val_accuracy: 0.8466 - lr: 5.0000e-04\n",
      "Epoch 12/30\n",
      "633/633 [==============================] - 144s 228ms/step - loss: 0.4484 - accuracy: 0.8087 - val_loss: 0.3616 - val_accuracy: 0.8485 - lr: 5.0000e-04\n",
      "Epoch 13/30\n",
      "633/633 [==============================] - 146s 231ms/step - loss: 0.4487 - accuracy: 0.8031 - val_loss: 0.4083 - val_accuracy: 0.8125 - lr: 5.0000e-04\n",
      "Epoch 14/30\n",
      "633/633 [==============================] - 141s 222ms/step - loss: 0.4436 - accuracy: 0.8079 - val_loss: 0.3651 - val_accuracy: 0.8371 - lr: 5.0000e-04\n",
      "Epoch 15/30\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.8130\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "633/633 [==============================] - 147s 232ms/step - loss: 0.4397 - accuracy: 0.8130 - val_loss: 0.3966 - val_accuracy: 0.8068 - lr: 5.0000e-04\n",
      "Epoch 16/30\n",
      "633/633 [==============================] - 133s 211ms/step - loss: 0.4295 - accuracy: 0.8165 - val_loss: 0.3525 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
      "Epoch 17/30\n",
      "633/633 [==============================] - 135s 213ms/step - loss: 0.4253 - accuracy: 0.8215 - val_loss: 0.3534 - val_accuracy: 0.8409 - lr: 2.5000e-04\n",
      "Epoch 18/30\n",
      "633/633 [==============================] - 152s 240ms/step - loss: 0.4157 - accuracy: 0.8241 - val_loss: 0.3505 - val_accuracy: 0.8371 - lr: 2.5000e-04\n",
      "Epoch 19/30\n",
      "633/633 [==============================] - 170s 268ms/step - loss: 0.4103 - accuracy: 0.8224 - val_loss: 0.3082 - val_accuracy: 0.8731 - lr: 2.5000e-04\n",
      "Epoch 20/30\n",
      "633/633 [==============================] - 164s 259ms/step - loss: 0.4050 - accuracy: 0.8278 - val_loss: 0.3140 - val_accuracy: 0.8598 - lr: 2.5000e-04\n",
      "Epoch 21/30\n",
      "633/633 [==============================] - 148s 233ms/step - loss: 0.3973 - accuracy: 0.8302 - val_loss: 0.3073 - val_accuracy: 0.8636 - lr: 2.5000e-04\n",
      "Epoch 22/30\n",
      "633/633 [==============================] - 139s 219ms/step - loss: 0.3901 - accuracy: 0.8348 - val_loss: 0.3203 - val_accuracy: 0.8636 - lr: 2.5000e-04\n",
      "Epoch 23/30\n",
      "633/633 [==============================] - 135s 213ms/step - loss: 0.3860 - accuracy: 0.8363 - val_loss: 0.3263 - val_accuracy: 0.8580 - lr: 2.5000e-04\n",
      "Epoch 24/30\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8349\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "633/633 [==============================] - 133s 210ms/step - loss: 0.3792 - accuracy: 0.8349 - val_loss: 0.3413 - val_accuracy: 0.8504 - lr: 2.5000e-04\n",
      "Epoch 25/30\n",
      "633/633 [==============================] - 135s 214ms/step - loss: 0.3684 - accuracy: 0.8419 - val_loss: 0.3130 - val_accuracy: 0.8731 - lr: 1.2500e-04\n",
      "Epoch 26/30\n",
      "633/633 [==============================] - 134s 211ms/step - loss: 0.3716 - accuracy: 0.8427 - val_loss: 0.2933 - val_accuracy: 0.8845 - lr: 1.2500e-04\n",
      "Epoch 27/30\n",
      "633/633 [==============================] - 133s 210ms/step - loss: 0.3642 - accuracy: 0.8432 - val_loss: 0.3317 - val_accuracy: 0.8712 - lr: 1.2500e-04\n",
      "Epoch 28/30\n",
      "633/633 [==============================] - 135s 213ms/step - loss: 0.3597 - accuracy: 0.8469 - val_loss: 0.3126 - val_accuracy: 0.8769 - lr: 1.2500e-04\n",
      "Epoch 29/30\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3565 - accuracy: 0.8494\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "633/633 [==============================] - 138s 218ms/step - loss: 0.3565 - accuracy: 0.8494 - val_loss: 0.3219 - val_accuracy: 0.8864 - lr: 1.2500e-04\n",
      "Epoch 30/30\n",
      "633/633 [==============================] - 145s 228ms/step - loss: 0.3525 - accuracy: 0.8469 - val_loss: 0.3144 - val_accuracy: 0.8826 - lr: 6.2500e-05\n",
      "Model saved as model_improve_6_combined.h5\n",
      "Evaluating the model on the test data\n",
      "33/33 [==============================] - 2s 48ms/step - loss: 0.3158 - accuracy: 0.8826\n",
      "Test Loss: 0.3158\n",
      "Test Accuracy: 0.8826\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Define paths\n",
    "base_dir = r'D:\\PKG - C-NMC 2019\\C-NMC_training_data'\n",
    "folds = ['fold_0', 'fold_1', 'fold_2']\n",
    "combined_dir = r'D:\\PKG - C-NMC 2019\\C-NMC_combined_data'\n",
    "all_dir = os.path.join(combined_dir, 'all')\n",
    "hem_dir = os.path.join(combined_dir, 'hem')\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 128, 128  \n",
    "batch_size = 16 \n",
    "epochs = 30  \n",
    "\n",
    "# Function to combine directories\n",
    "def combine_directories(base_dir, folds, all_dir, hem_dir):\n",
    "    if not os.path.exists(all_dir):\n",
    "        os.makedirs(all_dir)\n",
    "    if not os.path.exists(hem_dir):\n",
    "        os.makedirs(hem_dir)\n",
    "    \n",
    "    for fold in folds:\n",
    "        fold_dir = os.path.join(base_dir, fold)\n",
    "        for category in ['all', 'hem']:\n",
    "            category_dir = os.path.join(fold_dir, category)\n",
    "            combined_category_dir = all_dir if category == 'all' else hem_dir\n",
    "            if os.path.exists(category_dir):\n",
    "                for filename in os.listdir(category_dir):\n",
    "                    if filename.endswith('.bmp'):\n",
    "                        src = os.path.join(category_dir, filename)\n",
    "                        dst = os.path.join(combined_category_dir, filename)\n",
    "                        if not os.path.exists(dst):  # Avoid duplicates\n",
    "                            shutil.copy(src, dst)\n",
    "            else:\n",
    "                print(f\"Warning: The directory {category_dir} does not exist.\")\n",
    "\n",
    "combine_directories(base_dir, folds, all_dir, hem_dir)\n",
    "\n",
    "# Data Generator\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.05)  # 5% for validation\n",
    "\n",
    "def create_data_generators(combined_dir, img_width, img_height, batch_size):\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='training'  # 95% for training\n",
    "    )\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='validation'  # 5% for validation\n",
    "    )\n",
    "    return train_generator, test_generator\n",
    "\n",
    "train_generator, test_generator = create_data_generators(combined_dir, img_width, img_height, batch_size)\n",
    "\n",
    "# CNN model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(img_width, img_height, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='softplus', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks for dynamic learning rate and early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training with combined dataset\")\n",
    "model6 = create_model()\n",
    "history = model6.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model6.save('model_improve_6_combined.h5')\n",
    "print(\"Model saved as model_improve_6_combined.h5\")\n",
    "\n",
    "# Evaluating the model on the test data\n",
    "print(\"Evaluating the model on the test data\")\n",
    "test_loss, test_accuracy = model6.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10129 images belonging to 2 classes.\n",
      "Found 532 images belonging to 2 classes.\n",
      "Training with combined dataset\n",
      "Epoch 1/30\n",
      "633/633 [==============================] - 149s 233ms/step - loss: 0.5012 - accuracy: 0.7788 - val_loss: 0.4063 - val_accuracy: 0.8466 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "633/633 [==============================] - 139s 219ms/step - loss: 0.4713 - accuracy: 0.7980 - val_loss: 0.3931 - val_accuracy: 0.8314 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "633/633 [==============================] - 154s 244ms/step - loss: 0.4627 - accuracy: 0.7987 - val_loss: 0.3631 - val_accuracy: 0.8466 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "633/633 [==============================] - 167s 263ms/step - loss: 0.4609 - accuracy: 0.8025 - val_loss: 0.3909 - val_accuracy: 0.8220 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "633/633 [==============================] - 155s 245ms/step - loss: 0.4537 - accuracy: 0.8021 - val_loss: 0.4205 - val_accuracy: 0.8182 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.8030\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "633/633 [==============================] - 155s 244ms/step - loss: 0.4523 - accuracy: 0.8030 - val_loss: 0.4159 - val_accuracy: 0.8068 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "605/633 [===========================>..] - ETA: 6s - loss: 0.4410 - accuracy: 0.8090"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 119\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining with combined dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    118\u001b[0m model9 \u001b[38;5;241m=\u001b[39m create_model()\n\u001b[1;32m--> 119\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel9\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr_on_plateau\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m    129\u001b[0m model9\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_improve_9_combined.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chann\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chann\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chann\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chann\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chann\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chann\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chann\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chann\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chann\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Define paths\n",
    "base_dir = r'D:\\PKG - C-NMC 2019\\C-NMC_training_data'\n",
    "folds = ['fold_0', 'fold_1', 'fold_2']\n",
    "combined_dir = r'D:\\PKG - C-NMC 2019\\C-NMC_combined_data'\n",
    "all_dir = os.path.join(combined_dir, 'all')\n",
    "hem_dir = os.path.join(combined_dir, 'hem')\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 128, 128  \n",
    "batch_size = 16 \n",
    "epochs = 30  \n",
    "\n",
    "# Function to combine directories\n",
    "def combine_directories(base_dir, folds, all_dir, hem_dir):\n",
    "    if not os.path.exists(all_dir):\n",
    "        os.makedirs(all_dir)\n",
    "    if not os.path.exists(hem_dir):\n",
    "        os.makedirs(hem_dir)\n",
    "    \n",
    "    for fold in folds:\n",
    "        fold_dir = os.path.join(base_dir, fold)\n",
    "        for category in ['all', 'hem']:\n",
    "            category_dir = os.path.join(fold_dir, category)\n",
    "            combined_category_dir = all_dir if category == 'all' else hem_dir\n",
    "            if os.path.exists(category_dir):\n",
    "                for filename in os.listdir(category_dir):\n",
    "                    if filename.endswith('.bmp'):\n",
    "                        src = os.path.join(category_dir, filename)\n",
    "                        dst = os.path.join(combined_category_dir, filename)\n",
    "                        if not os.path.exists(dst):  # Avoid duplicates\n",
    "                            shutil.copy(src, dst)\n",
    "            else:\n",
    "                print(f\"Warning: The directory {category_dir} does not exist.\")\n",
    "\n",
    "combine_directories(base_dir, folds, all_dir, hem_dir)\n",
    "\n",
    "# Data Generator\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.05)  # 5% for validation\n",
    "\n",
    "def create_data_generators(combined_dir, img_width, img_height, batch_size):\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='training'  # 95% for training\n",
    "    )\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        combined_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='validation'  # 5% for validation\n",
    "    )\n",
    "    return train_generator, test_generator\n",
    "\n",
    "train_generator, test_generator = create_data_generators(combined_dir, img_width, img_height, batch_size)\n",
    "\n",
    "# CNN model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(img_width, img_height, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='softsign', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks for dynamic learning rate and early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training with combined dataset\")\n",
    "model9 = create_model()\n",
    "history = model9.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model9.save('model_improve_9_combined.h5')\n",
    "print(\"Model saved as model_improve_9_combined.h5\")\n",
    "\n",
    "# Evaluating the model on the test data\n",
    "print(\"Evaluating the model on the test data\")\n",
    "test_loss, test_accuracy = model9.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
